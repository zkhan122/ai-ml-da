{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\programs\\ai-ml-da\\pandas-learn\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "\n",
    "os.chdir(\"d:\\\\programs\\\\ai-ml-da\\\\pandas-learn\\\\\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.21</td>\n",
       "      <td>Premium</td>\n",
       "      <td>E</td>\n",
       "      <td>SI1</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Good</td>\n",
       "      <td>E</td>\n",
       "      <td>VS1</td>\n",
       "      <td>56.9</td>\n",
       "      <td>65.0</td>\n",
       "      <td>327</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.29</td>\n",
       "      <td>Premium</td>\n",
       "      <td>I</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>334</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.31</td>\n",
       "      <td>Good</td>\n",
       "      <td>J</td>\n",
       "      <td>SI2</td>\n",
       "      <td>63.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>335</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carat      cut color clarity  depth  table  price     x     y     z\n",
       "1   0.23    Ideal     E     SI2   61.5   55.0    326  3.95  3.98  2.43\n",
       "2   0.21  Premium     E     SI1   59.8   61.0    326  3.89  3.84  2.31\n",
       "3   0.23     Good     E     VS1   56.9   65.0    327  4.05  4.07  2.31\n",
       "4   0.29  Premium     I     VS2   62.4   58.0    334  4.20  4.23  2.63\n",
       "5   0.31     Good     J     SI2   63.3   58.0    335  4.34  4.35  2.75"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diamonds_df = pd.read_csv(\"datasets/diamonds.csv\", index_col=0)\n",
    "diamonds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53940, 10)\n",
      "Index(['carat', 'cut', 'color', 'clarity', 'depth', 'table', 'price', 'x', 'y',\n",
      "       'z'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(diamonds_df.shape)\n",
    "print(diamonds_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ideal', 'Premium', 'Good', 'Very Good', 'Fair'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see how many different types of cuts there are in the dataset\n",
    "diamonds_df[\"cut\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SI2', 'SI1', 'VS1', 'VS2', 'VVS2', 'VVS1', 'I1', 'IF'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see different classes of clarity there are in the dataset\n",
    "diamonds_df[\"clarity\"].unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## method to let pandas arbitrarily map coded ints to to each category in the df which is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series (1D array)\n",
    "\n",
    "# diamonds_df[\"cut\"].astype(\"category\").cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# but we will create codings manually\n",
    "cut_classes_dict = {\"Fair\" : 1, \"Good\" : 2, \"Very Good\" : 3, \"Premium\" : 4, \"Ideal\" : 5}\n",
    "clarity_classes_dict = {\"I1\" : 1, \"S12\" : 2, \"SI1\" : 3, \"VS2\" : 4, \"VS1\" : 5, \"VVS2\" : 6, \"VVS1\" : 7, \"IF\" : 8}\n",
    "color_classes_dict = {\"J\" : 1, \"I\" : 2, \"H\" : 3, \"G\" : 4, \"F\" : 5, \"E\" : 6, \"D\" : 7}\n",
    "\n",
    "# map\n",
    "diamonds_df[\"cut\"] = diamonds_df[\"cut\"].map(cut_classes_dict)\n",
    "diamonds_df[\"clarity\"] = diamonds_df[\"clarity\"].map(clarity_classes_dict)\n",
    "diamonds_df[\"color\"] = diamonds_df[\"color\"].map(color_classes_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.21</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.23</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>56.9</td>\n",
       "      <td>65.0</td>\n",
       "      <td>327</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.29</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>334</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.24</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>62.8</td>\n",
       "      <td>57.0</td>\n",
       "      <td>336</td>\n",
       "      <td>3.94</td>\n",
       "      <td>3.96</td>\n",
       "      <td>2.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.24</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>62.3</td>\n",
       "      <td>57.0</td>\n",
       "      <td>336</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carat  cut  color  clarity  depth  table  price     x     y     z\n",
       "2   0.21    4      6      3.0   59.8   61.0    326  3.89  3.84  2.31\n",
       "3   0.23    2      6      5.0   56.9   65.0    327  4.05  4.07  2.31\n",
       "4   0.29    4      2      4.0   62.4   58.0    334  4.20  4.23  2.63\n",
       "6   0.24    3      1      6.0   62.8   57.0    336  3.94  3.96  2.48\n",
       "7   0.24    3      2      7.0   62.3   57.0    336  3.95  3.98  2.47"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diamonds_df.dropna(inplace=True)\n",
    "diamonds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import svm, preprocessing\n",
    "\n",
    "diamonds_df = sklearn.utils.shuffle(diamonds_df)\n",
    "\n",
    "# feeding in our feature set\n",
    "X = diamonds_df.drop(\"price\", axis=1).values # we drop the Price col as we are projecting Price\n",
    "                                                # so we are getting vals of all cols except Price\n",
    "Y = diamonds_df[\"price\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.76, 2.  , 4.  , ..., 5.72, 5.8 , 3.72],\n",
       "       [0.54, 5.  , 4.  , ..., 5.24, 5.26, 3.25],\n",
       "       [0.2 , 4.  , 7.  , ..., 3.77, 3.72, 2.31],\n",
       "       ...,\n",
       "       [1.87, 5.  , 1.  , ..., 7.88, 7.82, 4.89],\n",
       "       [1.14, 5.  , 3.  , ..., 6.72, 6.74, 4.17],\n",
       "       [0.72, 4.  , 3.  , ..., 5.73, 5.69, 3.58]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44746, 9)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.shape(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0440482 , -1.77057821, -0.23235407, ...,  0.1167346 ,\n",
       "         0.18602742,  0.38754207],\n",
       "       [-0.45208536,  0.94945106, -0.23235407, ..., -0.32602859,\n",
       "        -0.31185816, -0.29861392],\n",
       "       [-1.21883722,  0.04277464,  1.54307542, ..., -1.68199087,\n",
       "        -1.73175408, -1.67092591],\n",
       "       ...,\n",
       "       [ 2.54726751,  0.94945106, -2.00778355, ...,  2.10916897,\n",
       "         2.0484883 ,  2.09563253],\n",
       "       [ 0.90100616,  0.94945106, -0.82416389, ...,  1.03915792,\n",
       "         1.05271714,  1.04449994],\n",
       "       [-0.0461579 ,  0.04277464, -0.82416389, ...,  0.12595884,\n",
       "         0.08460629,  0.18315518]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scaling the data using PreProcessing (simplifying data between 0 and 1 - Linear Coding)\n",
    "X = sklearn.preprocessing.scale(X)\n",
    "X\n",
    "# data has successfully been scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVR(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVR</label><div class=\"sk-toggleable__content\"><pre>SVR(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVR(kernel='linear')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_size = 200\n",
    "\n",
    "# things the model is gonna fit against (train on)\n",
    "X_train = X[:-test_size] # [:-test_size] FIRST 200 ROWS\n",
    "Y_train = Y[:-test_size]\n",
    "\n",
    "X_test = X[-test_size:]  # LAST 200 ROWS\n",
    "Y_test = Y[-test_size:] \n",
    "\n",
    "\n",
    "# defining the SVR (Support Vector Machine) Classifier:\n",
    "clf = svm.SVR(kernel=\"linear\")\n",
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.867855798954309\n"
     ]
    }
   ],
   "source": [
    "print(clf.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model predicts: 673.4155223440139, Actual value: 929\n",
      "Model predicts: 9710.193016534718, Actual value: 12437\n",
      "Model predicts: 575.9644407146625, Actual value: 873\n",
      "Model predicts: 3219.7465797962586, Actual value: 2575\n",
      "Model predicts: 2316.6515240585713, Actual value: 2030\n",
      "Model predicts: 4707.044863150064, Actual value: 4381\n",
      "Model predicts: 922.8616323455235, Actual value: 868\n",
      "Model predicts: 1364.6055853031385, Actual value: 1103\n",
      "Model predicts: 4374.5454948775705, Actual value: 3863\n",
      "Model predicts: 3479.7831740646147, Actual value: 3354\n",
      "Model predicts: 774.15905549121, Actual value: 694\n",
      "Model predicts: 4617.21925597679, Actual value: 5595\n",
      "Model predicts: 11886.142790716753, Actual value: 7294\n",
      "Model predicts: 3909.841870526734, Actual value: 3388\n",
      "Model predicts: 597.2012681958104, Actual value: 904\n",
      "Model predicts: 767.9093591417118, Actual value: 895\n",
      "Model predicts: 2102.6078830398637, Actual value: 1802\n",
      "Model predicts: 4245.7823289755015, Actual value: 3780\n",
      "Model predicts: 832.5785601906869, Actual value: 883\n",
      "Model predicts: 675.7846679632721, Actual value: 794\n",
      "Model predicts: 3810.396217854085, Actual value: 3439\n",
      "Model predicts: 5221.8744986647735, Actual value: 5704\n",
      "Model predicts: 5853.075492743723, Actual value: 7785\n",
      "Model predicts: 3898.9270162888847, Actual value: 3242\n",
      "Model predicts: 291.18299816100443, Actual value: 596\n",
      "Model predicts: 1519.39081885875, Actual value: 1377\n",
      "Model predicts: 3960.6546892096417, Actual value: 3739\n",
      "Model predicts: 3475.2082357728927, Actual value: 2956\n",
      "Model predicts: 1064.5084877478243, Actual value: 975\n",
      "Model predicts: 1956.7985332731414, Actual value: 1778\n",
      "Model predicts: 101.07669852020899, Actual value: 698\n",
      "Model predicts: 12149.0674320301, Actual value: 16149\n",
      "Model predicts: 1522.7676721794087, Actual value: 1056\n",
      "Model predicts: 5047.35292605761, Actual value: 5260\n",
      "Model predicts: 5962.064928398806, Actual value: 5102\n",
      "Model predicts: 643.8979799061881, Actual value: 671\n",
      "Model predicts: 14.697012622843886, Actual value: 776\n",
      "Model predicts: 4854.1750255621755, Actual value: 4505\n",
      "Model predicts: 1150.4315379424074, Actual value: 984\n",
      "Model predicts: 5420.571485583116, Actual value: 6465\n",
      "Model predicts: 779.4566530517254, Actual value: 789\n",
      "Model predicts: 503.99545425352335, Actual value: 911\n",
      "Model predicts: -279.69557112308894, Actual value: 462\n",
      "Model predicts: -247.59840342964435, Actual value: 467\n",
      "Model predicts: 1143.5323161464094, Actual value: 958\n",
      "Model predicts: 5807.758106165553, Actual value: 5395\n",
      "Model predicts: 5710.0902544613145, Actual value: 7597\n",
      "Model predicts: 6081.034352654882, Actual value: 4998\n",
      "Model predicts: 6752.255985960119, Actual value: 7260\n",
      "Model predicts: 3564.3967033067356, Actual value: 3179\n",
      "Model predicts: 9038.437748493328, Actual value: 10827\n",
      "Model predicts: 1161.569629933137, Actual value: 900\n",
      "Model predicts: 5936.794922980682, Actual value: 7521\n",
      "Model predicts: 1536.7625138691035, Actual value: 1303\n",
      "Model predicts: 486.84668483192763, Actual value: 702\n",
      "Model predicts: 7562.125103799773, Actual value: 11723\n",
      "Model predicts: 8284.991575203841, Actual value: 9653\n",
      "Model predicts: 6584.516601838323, Actual value: 10028\n",
      "Model predicts: 1593.2800371742617, Actual value: 1270\n",
      "Model predicts: 5428.373600843351, Actual value: 6399\n",
      "Model predicts: 3146.396523546462, Actual value: 2792\n",
      "Model predicts: 271.333281151552, Actual value: 608\n",
      "Model predicts: 3640.9131263064587, Actual value: 3354\n",
      "Model predicts: -42.99463678760776, Actual value: 513\n",
      "Model predicts: 1701.939979533688, Actual value: 1668\n",
      "Model predicts: 865.0152431180213, Actual value: 1024\n",
      "Model predicts: 3016.8067072985223, Actual value: 2394\n",
      "Model predicts: 5950.981074479672, Actual value: 5554\n",
      "Model predicts: 5637.24073765625, Actual value: 7887\n",
      "Model predicts: 7872.658110120839, Actual value: 10805\n",
      "Model predicts: 2850.385089493617, Actual value: 2423\n",
      "Model predicts: 5999.681994970926, Actual value: 5211\n",
      "Model predicts: 7419.834029719477, Actual value: 11880\n",
      "Model predicts: 5706.5748879227085, Actual value: 6670\n",
      "Model predicts: 5618.62980958108, Actual value: 4851\n",
      "Model predicts: 7174.735095743992, Actual value: 8676\n",
      "Model predicts: 412.5633128489035, Actual value: 945\n",
      "Model predicts: 2690.350224435853, Actual value: 2509\n",
      "Model predicts: 6905.805771822264, Actual value: 11115\n",
      "Model predicts: 4012.878206051486, Actual value: 3453\n",
      "Model predicts: 2421.2801475867313, Actual value: 2236\n",
      "Model predicts: 336.15924868544926, Actual value: 530\n",
      "Model predicts: -29.229538586318995, Actual value: 497\n",
      "Model predicts: 333.8422840825219, Actual value: 756\n",
      "Model predicts: 277.4778116317234, Actual value: 516\n",
      "Model predicts: 360.61566420804365, Actual value: 625\n",
      "Model predicts: 1066.2637661134995, Actual value: 961\n",
      "Model predicts: 118.43760456667133, Actual value: 689\n",
      "Model predicts: 945.3943462355674, Actual value: 820\n",
      "Model predicts: 4924.417480149215, Actual value: 3415\n",
      "Model predicts: 4734.9804969397965, Actual value: 4528\n",
      "Model predicts: 275.09495910923624, Actual value: 844\n",
      "Model predicts: 501.7010485470814, Actual value: 620\n",
      "Model predicts: 618.4921910329981, Actual value: 730\n",
      "Model predicts: 618.0132698369339, Actual value: 752\n",
      "Model predicts: 1883.6760836794165, Actual value: 1621\n",
      "Model predicts: 12381.33341911458, Actual value: 18077\n",
      "Model predicts: 8961.47331223225, Actual value: 13080\n",
      "Model predicts: 532.0123438634951, Actual value: 906\n",
      "Model predicts: 874.2592198609909, Actual value: 978\n",
      "Model predicts: 6834.67434645117, Actual value: 6581\n",
      "Model predicts: 3380.271875797955, Actual value: 2699\n",
      "Model predicts: 543.9449499686466, Actual value: 898\n",
      "Model predicts: 2187.579226851069, Actual value: 1668\n",
      "Model predicts: 3195.2527729082085, Actual value: 2586\n",
      "Model predicts: 2848.3298441586057, Actual value: 2316\n",
      "Model predicts: 5713.591451064469, Actual value: 5363\n",
      "Model predicts: 1225.1426364656977, Actual value: 943\n",
      "Model predicts: 32.8393756737737, Actual value: 698\n",
      "Model predicts: 934.6477838483929, Actual value: 988\n",
      "Model predicts: 4261.1993775478095, Actual value: 4325\n",
      "Model predicts: 2252.836146964356, Actual value: 1810\n",
      "Model predicts: 1317.4763259623815, Actual value: 1129\n",
      "Model predicts: 3803.8938759979224, Actual value: 3890\n",
      "Model predicts: 3101.0726603111375, Actual value: 2553\n",
      "Model predicts: 984.2558413924362, Actual value: 1125\n",
      "Model predicts: 2255.084665400427, Actual value: 2889\n",
      "Model predicts: 715.762439922486, Actual value: 827\n",
      "Model predicts: 220.9878392656001, Actual value: 600\n",
      "Model predicts: 3435.706029241249, Actual value: 2898\n",
      "Model predicts: 3179.3737747401547, Actual value: 2184\n",
      "Model predicts: 951.2321176380165, Actual value: 842\n",
      "Model predicts: 4516.200783494931, Actual value: 4801\n",
      "Model predicts: 2017.0711532949792, Actual value: 1847\n",
      "Model predicts: 5237.97603236044, Actual value: 6479\n",
      "Model predicts: 5057.44041093763, Actual value: 5497\n",
      "Model predicts: 2986.50837115088, Actual value: 2318\n",
      "Model predicts: 8672.23406730833, Actual value: 10497\n",
      "Model predicts: 2983.699376544497, Actual value: 2559\n",
      "Model predicts: 5190.1323472142485, Actual value: 4969\n",
      "Model predicts: 1524.9433686045406, Actual value: 1147\n",
      "Model predicts: 1165.4501735885415, Actual value: 1060\n",
      "Model predicts: 3291.562206306746, Actual value: 2686\n",
      "Model predicts: 2857.5863545034563, Actual value: 3656\n",
      "Model predicts: 6082.291293835988, Actual value: 6322\n",
      "Model predicts: 6725.561276243109, Actual value: 6025\n",
      "Model predicts: 1723.6708273850697, Actual value: 1554\n",
      "Model predicts: 3014.365583534803, Actual value: 2360\n",
      "Model predicts: 2989.472699598055, Actual value: 2382\n",
      "Model predicts: 1044.2811014488907, Actual value: 967\n",
      "Model predicts: 5868.688612348213, Actual value: 7876\n",
      "Model predicts: 525.8618646341138, Actual value: 755\n",
      "Model predicts: 1475.7828481593594, Actual value: 1367\n",
      "Model predicts: 5996.362765986634, Actual value: 4234\n",
      "Model predicts: 1091.9454363144173, Actual value: 961\n",
      "Model predicts: 3902.5832817575047, Actual value: 3734\n",
      "Model predicts: 3340.938105380824, Actual value: 2765\n",
      "Model predicts: 1653.632951740023, Actual value: 1427\n",
      "Model predicts: 2181.9569399733855, Actual value: 1913\n",
      "Model predicts: 1078.1660510971037, Actual value: 898\n",
      "Model predicts: 6459.862717627767, Actual value: 7548\n",
      "Model predicts: 1961.6535249180517, Actual value: 1966\n",
      "Model predicts: 559.984497331649, Actual value: 741\n",
      "Model predicts: 9893.311320162018, Actual value: 11526\n",
      "Model predicts: 5376.827980217271, Actual value: 5778\n",
      "Model predicts: 855.4549535516376, Actual value: 1080\n",
      "Model predicts: 3145.6727261533233, Actual value: 1844\n",
      "Model predicts: -25.74567761288563, Actual value: 473\n",
      "Model predicts: 1273.7144341784942, Actual value: 1048\n",
      "Model predicts: 269.1503467211119, Actual value: 757\n",
      "Model predicts: 6071.517701740206, Actual value: 7862\n",
      "Model predicts: 2260.9351921215602, Actual value: 1963\n",
      "Model predicts: 576.4039092360413, Actual value: 738\n",
      "Model predicts: 2043.5210809701493, Actual value: 1698\n",
      "Model predicts: 5360.011719077697, Actual value: 5880\n",
      "Model predicts: 4976.986808368707, Actual value: 4032\n",
      "Model predicts: 573.7139188166379, Actual value: 707\n",
      "Model predicts: 3351.66159329497, Actual value: 3112\n",
      "Model predicts: 1965.9999247711858, Actual value: 1854\n",
      "Model predicts: 847.5751107504348, Actual value: 710\n",
      "Model predicts: 3563.0478383039563, Actual value: 3192\n",
      "Model predicts: 2886.9261060267, Actual value: 2730\n",
      "Model predicts: 5186.779161842853, Actual value: 4465\n",
      "Model predicts: 2114.5682435906, Actual value: 1956\n",
      "Model predicts: 1806.5530310088848, Actual value: 1656\n",
      "Model predicts: 3516.7648627335184, Actual value: 3446\n",
      "Model predicts: 716.6733466992064, Actual value: 694\n",
      "Model predicts: 4643.617233718571, Actual value: 4253\n",
      "Model predicts: 2550.3072863607777, Actual value: 1968\n",
      "Model predicts: 5546.9603522781545, Actual value: 7539\n",
      "Model predicts: 341.28841456282635, Actual value: 658\n",
      "Model predicts: 616.8027686418936, Actual value: 754\n",
      "Model predicts: 3728.3208912062632, Actual value: 3716\n",
      "Model predicts: 1169.3290756102501, Actual value: 892\n",
      "Model predicts: 658.3923058820797, Actual value: 663\n",
      "Model predicts: 8826.394494026974, Actual value: 8033\n",
      "Model predicts: 1326.6753868790256, Actual value: 1244\n",
      "Model predicts: 3379.1680553057367, Actual value: 2836\n",
      "Model predicts: 576.7923543405427, Actual value: 844\n",
      "Model predicts: 5871.6469858944, Actual value: 8303\n",
      "Model predicts: 3251.0094706499585, Actual value: 2848\n",
      "Model predicts: 424.19738584447805, Actual value: 780\n",
      "Model predicts: 7488.555616587748, Actual value: 13015\n",
      "Model predicts: 1049.4562412609712, Actual value: 791\n",
      "Model predicts: -419.9557567722113, Actual value: 461\n",
      "Model predicts: 4531.234163215497, Actual value: 3869\n",
      "Model predicts: 5766.918418683839, Actual value: 5767\n",
      "Model predicts: 10979.203054519807, Actual value: 10137\n",
      "Model predicts: 6100.487654624823, Actual value: 6628\n",
      "Model predicts: 2660.13923776766, Actual value: 2398\n"
     ]
    }
   ],
   "source": [
    "# now lets step through the model and see how it is making predictions along with an accuracy for each test \n",
    "for X, Y in zip(X_test, Y_test):\n",
    "    print(f\"Model predicts: {clf.predict([X])[0]}, Actual value: {Y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6525206306140094\n"
     ]
    }
   ],
   "source": [
    "clf2 = svm.SVR(kernel=\"rbf\")\n",
    "clf2.fit(X_train, Y_train)\n",
    "\n",
    "print(clf2.score(X_test, Y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model predicts: 841.1254186240471, Actual Value: 929\n",
      "Model predicts: 5277.302858468897, Actual Value: 12437\n",
      "Model predicts: 934.0414181053247, Actual Value: 873\n",
      "Model predicts: 2566.7257448818827, Actual Value: 2575\n",
      "Model predicts: 2013.3836471727066, Actual Value: 2030\n",
      "Model predicts: 3697.256423280345, Actual Value: 4381\n",
      "Model predicts: 1101.1000684644678, Actual Value: 868\n",
      "Model predicts: 1210.186210081032, Actual Value: 1103\n",
      "Model predicts: 4083.312593298068, Actual Value: 3863\n",
      "Model predicts: 3249.6779055503907, Actual Value: 3354\n",
      "Model predicts: 1225.054867435691, Actual Value: 694\n",
      "Model predicts: 4469.7013036724, Actual Value: 5595\n",
      "Model predicts: 3328.5122918142006, Actual Value: 7294\n",
      "Model predicts: 3742.4276373602725, Actual Value: 3388\n",
      "Model predicts: 848.8087701271843, Actual Value: 904\n",
      "Model predicts: 1193.7742710125247, Actual Value: 895\n",
      "Model predicts: 1841.6168113293695, Actual Value: 1802\n",
      "Model predicts: 3989.2682775774783, Actual Value: 3780\n",
      "Model predicts: 694.6089028828746, Actual Value: 883\n",
      "Model predicts: 2454.391341223718, Actual Value: 794\n",
      "Model predicts: 3711.2730243044284, Actual Value: 3439\n",
      "Model predicts: 5018.585513186096, Actual Value: 5704\n",
      "Model predicts: 4896.443428238773, Actual Value: 7785\n",
      "Model predicts: 3577.9308669459087, Actual Value: 3242\n",
      "Model predicts: 1315.0552515514419, Actual Value: 596\n",
      "Model predicts: 1439.4419228030815, Actual Value: 1377\n",
      "Model predicts: 3262.911297760804, Actual Value: 3739\n",
      "Model predicts: 3033.3703409242344, Actual Value: 2956\n",
      "Model predicts: 933.7169438037199, Actual Value: 975\n",
      "Model predicts: 1766.7296955038069, Actual Value: 1778\n",
      "Model predicts: 942.2992821271005, Actual Value: 698\n",
      "Model predicts: 5061.844674257889, Actual Value: 16149\n",
      "Model predicts: 1475.158301399441, Actual Value: 1056\n",
      "Model predicts: 5116.7423926126285, Actual Value: 5260\n",
      "Model predicts: 5152.930890596506, Actual Value: 5102\n",
      "Model predicts: 909.9719443270806, Actual Value: 671\n",
      "Model predicts: 969.1461158519269, Actual Value: 776\n",
      "Model predicts: 3669.6532884364583, Actual Value: 4505\n",
      "Model predicts: 1122.413016809391, Actual Value: 984\n",
      "Model predicts: 4989.111786081935, Actual Value: 6465\n",
      "Model predicts: 827.9175080748514, Actual Value: 789\n",
      "Model predicts: 1081.2399318030054, Actual Value: 911\n",
      "Model predicts: 622.9698930476034, Actual Value: 462\n",
      "Model predicts: 823.955966952135, Actual Value: 467\n",
      "Model predicts: 926.3705407504162, Actual Value: 958\n",
      "Model predicts: 6006.31976671126, Actual Value: 5395\n",
      "Model predicts: 5465.042656657795, Actual Value: 7597\n",
      "Model predicts: 5372.396970988835, Actual Value: 4998\n",
      "Model predicts: 6195.509985559751, Actual Value: 7260\n",
      "Model predicts: 3190.6187161663797, Actual Value: 3179\n",
      "Model predicts: 7062.064533212261, Actual Value: 10827\n",
      "Model predicts: 1228.633969361091, Actual Value: 900\n",
      "Model predicts: 5814.837625438032, Actual Value: 7521\n",
      "Model predicts: 1472.5482037721542, Actual Value: 1303\n",
      "Model predicts: 748.3416568182483, Actual Value: 702\n",
      "Model predicts: 6273.088266362263, Actual Value: 11723\n",
      "Model predicts: 6682.500205648332, Actual Value: 9653\n",
      "Model predicts: 6182.717565774161, Actual Value: 10028\n",
      "Model predicts: 1779.7707564087025, Actual Value: 1270\n",
      "Model predicts: 5078.611915880658, Actual Value: 6399\n",
      "Model predicts: 2845.8125604322067, Actual Value: 2792\n",
      "Model predicts: 952.2744121168876, Actual Value: 608\n",
      "Model predicts: 3288.4425969882636, Actual Value: 3354\n",
      "Model predicts: 898.2459639817735, Actual Value: 513\n",
      "Model predicts: 2285.448811121834, Actual Value: 1668\n",
      "Model predicts: 747.3466136167626, Actual Value: 1024\n",
      "Model predicts: 2774.102373073357, Actual Value: 2394\n",
      "Model predicts: 5892.201344409987, Actual Value: 5554\n",
      "Model predicts: 5760.912817572075, Actual Value: 7887\n",
      "Model predicts: 6112.817760025477, Actual Value: 10805\n",
      "Model predicts: 2734.5573699861693, Actual Value: 2423\n",
      "Model predicts: 5258.153998061727, Actual Value: 5211\n",
      "Model predicts: 5765.152173318476, Actual Value: 11880\n",
      "Model predicts: 5030.207306920029, Actual Value: 6670\n",
      "Model predicts: 4991.96408578174, Actual Value: 4851\n",
      "Model predicts: 6765.480066586997, Actual Value: 8676\n",
      "Model predicts: 1989.0094573767929, Actual Value: 945\n",
      "Model predicts: 2261.486103868104, Actual Value: 2509\n",
      "Model predicts: 6117.387238738183, Actual Value: 11115\n",
      "Model predicts: 3987.260899218003, Actual Value: 3453\n",
      "Model predicts: 1938.680713951839, Actual Value: 2236\n",
      "Model predicts: 1023.312359906221, Actual Value: 530\n",
      "Model predicts: 557.9265269106263, Actual Value: 497\n",
      "Model predicts: 887.5382688528707, Actual Value: 756\n",
      "Model predicts: 982.4190120624676, Actual Value: 516\n",
      "Model predicts: 618.9319671385529, Actual Value: 625\n",
      "Model predicts: 832.2873595422211, Actual Value: 961\n",
      "Model predicts: 336.517173304459, Actual Value: 689\n",
      "Model predicts: 888.5588519948956, Actual Value: 820\n",
      "Model predicts: 3756.293998978606, Actual Value: 3415\n",
      "Model predicts: 4110.626423419278, Actual Value: 4528\n",
      "Model predicts: 910.7600855618639, Actual Value: 844\n",
      "Model predicts: 811.1336643477784, Actual Value: 620\n",
      "Model predicts: 736.3265329538217, Actual Value: 730\n",
      "Model predicts: 666.3553735671912, Actual Value: 752\n",
      "Model predicts: 1596.8346875751715, Actual Value: 1621\n",
      "Model predicts: 5972.108425689314, Actual Value: 18077\n",
      "Model predicts: 6503.888043861245, Actual Value: 13080\n",
      "Model predicts: 569.4941149300162, Actual Value: 906\n",
      "Model predicts: 1727.211332575316, Actual Value: 978\n",
      "Model predicts: 5843.707707310066, Actual Value: 6581\n",
      "Model predicts: 2996.9660818587236, Actual Value: 2699\n",
      "Model predicts: 857.2185196476357, Actual Value: 898\n",
      "Model predicts: 1840.5834733656113, Actual Value: 1668\n",
      "Model predicts: 3081.601375369253, Actual Value: 2586\n",
      "Model predicts: 2698.2063572986235, Actual Value: 2316\n",
      "Model predicts: 5493.817314428406, Actual Value: 5363\n",
      "Model predicts: 939.5197902868435, Actual Value: 943\n",
      "Model predicts: 431.20545159006633, Actual Value: 698\n",
      "Model predicts: 1161.9869075576091, Actual Value: 988\n",
      "Model predicts: 4143.0015544627995, Actual Value: 4325\n",
      "Model predicts: 1936.0960210608644, Actual Value: 1810\n",
      "Model predicts: 1046.7514966540919, Actual Value: 1129\n",
      "Model predicts: 3641.390681831307, Actual Value: 3890\n",
      "Model predicts: 2981.3752531597393, Actual Value: 2553\n",
      "Model predicts: 835.6052046902723, Actual Value: 1125\n",
      "Model predicts: 1863.2221309697518, Actual Value: 2889\n",
      "Model predicts: 1126.327256349334, Actual Value: 827\n",
      "Model predicts: 1120.5962663339233, Actual Value: 600\n",
      "Model predicts: 3354.666430167824, Actual Value: 2898\n",
      "Model predicts: 2923.191871542421, Actual Value: 2184\n",
      "Model predicts: 978.2743693488956, Actual Value: 842\n",
      "Model predicts: 4798.383481390255, Actual Value: 4801\n",
      "Model predicts: 1628.982957384251, Actual Value: 1847\n",
      "Model predicts: 4748.38944519992, Actual Value: 6479\n",
      "Model predicts: 5011.329792057844, Actual Value: 5497\n",
      "Model predicts: 2632.735913945293, Actual Value: 2318\n",
      "Model predicts: 7009.890999260792, Actual Value: 10497\n",
      "Model predicts: 2892.2872115979035, Actual Value: 2559\n",
      "Model predicts: 4961.19871219047, Actual Value: 4969\n",
      "Model predicts: 2136.8948002786733, Actual Value: 1147\n",
      "Model predicts: 1158.4766347110321, Actual Value: 1060\n",
      "Model predicts: 3156.5456978295506, Actual Value: 2686\n",
      "Model predicts: 2731.4712478368942, Actual Value: 3656\n",
      "Model predicts: 6055.498775721102, Actual Value: 6322\n",
      "Model predicts: 5373.91258501662, Actual Value: 6025\n",
      "Model predicts: 1516.8180522494392, Actual Value: 1554\n",
      "Model predicts: 2793.302625015705, Actual Value: 2360\n",
      "Model predicts: 2872.4342709782977, Actual Value: 2382\n",
      "Model predicts: 1485.1719146686983, Actual Value: 967\n",
      "Model predicts: 5742.261299199296, Actual Value: 7876\n",
      "Model predicts: 1281.3855304086903, Actual Value: 755\n",
      "Model predicts: 2258.247253749886, Actual Value: 1367\n",
      "Model predicts: 4760.552287981897, Actual Value: 4234\n",
      "Model predicts: 872.240172007861, Actual Value: 961\n",
      "Model predicts: 3441.7357865028935, Actual Value: 3734\n",
      "Model predicts: 3226.5007062384925, Actual Value: 2765\n",
      "Model predicts: 1492.676785258771, Actual Value: 1427\n",
      "Model predicts: 1799.360966316074, Actual Value: 1913\n",
      "Model predicts: 1117.9925987412962, Actual Value: 898\n",
      "Model predicts: 6235.439492808318, Actual Value: 7548\n",
      "Model predicts: 2153.6138929818576, Actual Value: 1966\n",
      "Model predicts: 700.2740848994003, Actual Value: 741\n",
      "Model predicts: 4943.517055421065, Actual Value: 11526\n",
      "Model predicts: 4458.444948436129, Actual Value: 5778\n",
      "Model predicts: 588.7438043078723, Actual Value: 1080\n",
      "Model predicts: 2748.875123989687, Actual Value: 1844\n",
      "Model predicts: 914.7952938600097, Actual Value: 473\n",
      "Model predicts: 1155.9580191965183, Actual Value: 1048\n",
      "Model predicts: 602.731289973909, Actual Value: 757\n",
      "Model predicts: 5527.770947944136, Actual Value: 7862\n",
      "Model predicts: 1761.78141003773, Actual Value: 1963\n",
      "Model predicts: 806.6343899179883, Actual Value: 738\n",
      "Model predicts: 1747.925452704507, Actual Value: 1698\n",
      "Model predicts: 4627.140643244011, Actual Value: 5880\n",
      "Model predicts: 4364.758000171612, Actual Value: 4032\n",
      "Model predicts: 824.2271448115935, Actual Value: 707\n",
      "Model predicts: 3191.528510525477, Actual Value: 3112\n",
      "Model predicts: 1738.432200720254, Actual Value: 1854\n",
      "Model predicts: 919.2758561733654, Actual Value: 710\n",
      "Model predicts: 3581.714816648268, Actual Value: 3192\n",
      "Model predicts: 2638.9867803988186, Actual Value: 2730\n",
      "Model predicts: 4441.294170594923, Actual Value: 4465\n",
      "Model predicts: 1773.4526754935482, Actual Value: 1956\n",
      "Model predicts: 1391.0358135187082, Actual Value: 1656\n",
      "Model predicts: 3265.121550132648, Actual Value: 3446\n",
      "Model predicts: 919.0818265706198, Actual Value: 694\n",
      "Model predicts: 3971.3029866644683, Actual Value: 4253\n",
      "Model predicts: 2566.21768087665, Actual Value: 1968\n",
      "Model predicts: 5573.3288670537095, Actual Value: 7539\n",
      "Model predicts: 729.7499927056838, Actual Value: 658\n",
      "Model predicts: 884.4040673869886, Actual Value: 754\n",
      "Model predicts: 3343.0866415536484, Actual Value: 3716\n",
      "Model predicts: 1108.960372133002, Actual Value: 892\n",
      "Model predicts: 1172.28300285394, Actual Value: 663\n",
      "Model predicts: 6955.204133275822, Actual Value: 8033\n",
      "Model predicts: 1327.2559420279588, Actual Value: 1244\n",
      "Model predicts: 3286.485213694569, Actual Value: 2836\n",
      "Model predicts: 906.9858485309392, Actual Value: 844\n",
      "Model predicts: 5145.723098357375, Actual Value: 8303\n",
      "Model predicts: 3029.9990572961337, Actual Value: 2848\n",
      "Model predicts: 1061.3321254836742, Actual Value: 780\n",
      "Model predicts: 5492.507401392513, Actual Value: 13015\n",
      "Model predicts: 1248.797307125701, Actual Value: 791\n",
      "Model predicts: 1229.2044860208332, Actual Value: 461\n",
      "Model predicts: 3442.5144175365976, Actual Value: 3869\n",
      "Model predicts: 4729.093324572603, Actual Value: 5767\n",
      "Model predicts: 5575.466547812623, Actual Value: 10137\n",
      "Model predicts: 5453.14603398988, Actual Value: 6628\n",
      "Model predicts: 2566.3836105473333, Actual Value: 2398\n"
     ]
    }
   ],
   "source": [
    "for X, Y in zip(X_test, Y_test):\n",
    "    print(f\"Model predicts: {clf2.predict([X])[0]}, Actual Value: {Y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can see different types of models for our classifiers give different accuracies, where e.g. In this case kernel=linear regression gives better accuracy than kernel=rbf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So overall, we covered the basics of analyzing data using pandas so now from here to get a deeper understanding, we should dive deeper into the intricacies behind how these models work and the algorithms used to create them."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
