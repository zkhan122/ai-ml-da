{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reading the dataset in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neo_id</th>\n",
       "      <th>name</th>\n",
       "      <th>absolute_magnitude</th>\n",
       "      <th>estimated_diameter_min</th>\n",
       "      <th>estimated_diameter_max</th>\n",
       "      <th>orbiting_body</th>\n",
       "      <th>relative_velocity</th>\n",
       "      <th>miss_distance</th>\n",
       "      <th>is_hazardous</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2162117</td>\n",
       "      <td>162117 (1998 SD15)</td>\n",
       "      <td>19.14</td>\n",
       "      <td>0.394962</td>\n",
       "      <td>0.883161</td>\n",
       "      <td>Earth</td>\n",
       "      <td>71745.401048</td>\n",
       "      <td>5.814362e+07</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2349507</td>\n",
       "      <td>349507 (2008 QY)</td>\n",
       "      <td>18.50</td>\n",
       "      <td>0.530341</td>\n",
       "      <td>1.185878</td>\n",
       "      <td>Earth</td>\n",
       "      <td>109949.757148</td>\n",
       "      <td>5.580105e+07</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2455415</td>\n",
       "      <td>455415 (2003 GA)</td>\n",
       "      <td>21.45</td>\n",
       "      <td>0.136319</td>\n",
       "      <td>0.304818</td>\n",
       "      <td>Earth</td>\n",
       "      <td>24865.506798</td>\n",
       "      <td>6.720689e+07</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3132126</td>\n",
       "      <td>(2002 PB)</td>\n",
       "      <td>20.63</td>\n",
       "      <td>0.198863</td>\n",
       "      <td>0.444672</td>\n",
       "      <td>Earth</td>\n",
       "      <td>78890.076805</td>\n",
       "      <td>3.039644e+07</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3557844</td>\n",
       "      <td>(2011 DW)</td>\n",
       "      <td>22.70</td>\n",
       "      <td>0.076658</td>\n",
       "      <td>0.171412</td>\n",
       "      <td>Earth</td>\n",
       "      <td>56036.519484</td>\n",
       "      <td>6.311863e+07</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    neo_id                name  absolute_magnitude  estimated_diameter_min  \\\n",
       "0  2162117  162117 (1998 SD15)               19.14                0.394962   \n",
       "1  2349507    349507 (2008 QY)               18.50                0.530341   \n",
       "2  2455415    455415 (2003 GA)               21.45                0.136319   \n",
       "3  3132126           (2002 PB)               20.63                0.198863   \n",
       "4  3557844           (2011 DW)               22.70                0.076658   \n",
       "\n",
       "   estimated_diameter_max orbiting_body  relative_velocity  miss_distance  \\\n",
       "0                0.883161         Earth       71745.401048   5.814362e+07   \n",
       "1                1.185878         Earth      109949.757148   5.580105e+07   \n",
       "2                0.304818         Earth       24865.506798   6.720689e+07   \n",
       "3                0.444672         Earth       78890.076805   3.039644e+07   \n",
       "4                0.171412         Earth       56036.519484   6.311863e+07   \n",
       "\n",
       "   is_hazardous  \n",
       "0         False  \n",
       "1          True  \n",
       "2         False  \n",
       "3         False  \n",
       "4         False  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_pth = \"../datasets/nearest-earth-objects.csv\"\n",
    "df = pd.read_csv(dataset_pth) # dataframe\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 338199 entries, 0 to 338198\n",
      "Data columns (total 9 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   neo_id                  338199 non-null  int64  \n",
      " 1   name                    338199 non-null  object \n",
      " 2   absolute_magnitude      338171 non-null  float64\n",
      " 3   estimated_diameter_min  338171 non-null  float64\n",
      " 4   estimated_diameter_max  338171 non-null  float64\n",
      " 5   orbiting_body           338199 non-null  object \n",
      " 6   relative_velocity       338199 non-null  float64\n",
      " 7   miss_distance           338199 non-null  float64\n",
      " 8   is_hazardous            338199 non-null  bool   \n",
      "dtypes: bool(1), float64(5), int64(1), object(2)\n",
      "memory usage: 21.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## checking all null entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neo_id                     0\n",
       "name                       0\n",
       "absolute_magnitude        28\n",
       "estimated_diameter_min    28\n",
       "estimated_diameter_max    28\n",
       "orbiting_body              0\n",
       "relative_velocity          0\n",
       "miss_distance              0\n",
       "is_hazardous               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating a subset of the original data (don't need to use all of it) -  if no nulls then we don't need to dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neo_id                    0\n",
       "name                      0\n",
       "absolute_magnitude        0\n",
       "estimated_diameter_min    0\n",
       "estimated_diameter_max    0\n",
       "orbiting_body             0\n",
       "relative_velocity         0\n",
       "miss_distance             0\n",
       "is_hazardous              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_subset = df.head(300) # selecting a subset of the dataset\n",
    "\n",
    "df_subset.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## we can count the number of hazardous asteroid objects and non-hazardous asteroid objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_hazardous\n",
       "False    255\n",
       "True      45\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_subset[\"is_hazardous\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      False\n",
      "1       True\n",
      "2      False\n",
      "3      False\n",
      "4      False\n",
      "       ...  \n",
      "295     True\n",
      "296     True\n",
      "297    False\n",
      "298    False\n",
      "299    False\n",
      "Name: is_hazardous, Length: 300, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "y = df_subset.iloc[:, -1] # set the target set to be only the last column\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_hazardous\n",
       "False    255\n",
       "True      45\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_subset[\"is_hazardous\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## converting target set Y to 0 or 1 for binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0\n",
      "1      1\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "295    1\n",
      "296    1\n",
      "297    0\n",
      "298    0\n",
      "299    0\n",
      "Name: is_hazardous, Length: 300, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mw/8tv2pqjn0kx4nlmm893wbfg00000gp/T/ipykernel_4254/1818337623.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_subset[\"is_hazardous\"] = df[\"is_hazardous\"].astype(int)\n"
     ]
    }
   ],
   "source": [
    "df_subset[\"is_hazardous\"] = df[\"is_hazardous\"].astype(int)\n",
    "\n",
    "print(df_subset[\"is_hazardous\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating our feature set and target set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     absolute_magnitude  estimated_diameter_max\n",
      "0                 19.14                0.883161\n",
      "1                 18.50                1.185878\n",
      "2                 21.45                0.304818\n",
      "3                 20.63                0.444672\n",
      "4                 22.70                0.171412\n",
      "..                  ...                     ...\n",
      "295               21.10                0.358129\n",
      "296               21.94                0.243243\n",
      "297               23.77                0.104722\n",
      "298               26.78                0.026184\n",
      "299               24.40                0.078350\n",
      "\n",
      "[300 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "X = df_subset[[\"absolute_magnitude\", \"estimated_diameter_max\"]]\n",
    "y = df_subset[\"is_hazardous\"]\n",
    "\n",
    "\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## we define the activation function - we are using sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z): # g = f(x) =  1 / 1 + e^(-z)\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing activation to see if initial computation is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8807970779778823"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we define our dense function which computes the activations of the dense layer for forward propagation where dense refers to a NN in which each layer is deeply connected to the prev. layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# needs to return activation_output which is to be fed to next layer\n",
    "def dense(activation_input, W, b): # activation_in is X\n",
    "    units = W.shape[1]\n",
    "    activation_output = np.zeros(units)\n",
    "    for j in range(units):\n",
    "        w = W[:, j] # same as W[j] but for clarity I will keep it as it is\n",
    "        z = np.dot(w, activation_input) + b[j] # Wx + b\n",
    "        activation_output = sigmoid(z)\n",
    "    return activation_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_activation(z):\n",
    "    return np.maximum(0, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's build a very simple 3-layer neural network using dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_sequential_model(x, W1, b1, W2, b2, W3, b3, W4, b4):\n",
    "    activation_layer1 = dense(x, W1, b1)\n",
    "    activation_layer2 = relu_activation(dense(activation_layer1, W2, b2))\n",
    "    activation_layer3 = relu_activation(dense(activation_layer2, W3, b3))\n",
    "    activation_layer4 = dense(activation_layer3, W4, b4)\n",
    "    return activation_layer4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setting some random weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # First hidden layer\n",
    "# W1_tmp = np.array([\n",
    "#     [-0.58,  0.76,  0.91],\n",
    "#     [ 0.23, -0.82, -0.44]\n",
    "# ])\n",
    "# b1_tmp = np.array([-0.37,  0.51, -0.63])\n",
    "\n",
    "# # Second hidden layer\n",
    "# W2_tmp = np.array([\n",
    "#     [ 0.71, -0.52,  0.43],\n",
    "#     [-0.33,  0.61,  0.29],\n",
    "#     [ 0.95, -0.79, -0.40]\n",
    "# ])\n",
    "# b2_tmp = np.array([0.12, -0.38,  0.76])\n",
    "\n",
    "# # Output layer\n",
    "# W3_tmp = np.array([[-0.86],\n",
    "#                    [ 0.35],\n",
    "#                    [-0.67]\n",
    "#                    ])\n",
    "# b3_tmp = np.array([0.21])\n",
    "\n",
    "W1_tmp = np.random.uniform(low=-1.0, high=1.0, size=(2, 3))\n",
    "b1_tmp = np.random.uniform(low=-1.0, high=1.0, size=(3,))\n",
    "\n",
    "W2_tmp = np.random.uniform(low=-1.0, high=1.0, size=(3, 3))\n",
    "b2_tmp = np.random.uniform(low=-1.0, high=1.0, size=(3,))\n",
    "\n",
    "W3_tmp = np.random.uniform(low=-1.0, high=1.0, size=(3, 3))\n",
    "b3_tmp = np.random.uniform(low=-1.0, high=1.0, size=(3,))\n",
    "\n",
    "\n",
    "W4_tmp = np.random.uniform(low=-1.0, high=1.0, size=(3, 1))\n",
    "b4_tmp = np.random.uniform(low=-1.0, high=1.0, size=(1,))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can define our predict function which basically makes predictions for each sample (0 or 1) -> (non-hazardous or hazardous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, W1, b1, W2, b2, W3, b3, w4, b4):\n",
    "    ## m = number of training examples  - rows\n",
    "    m = X.shape[0]\n",
    "    predictions_buffer = np.zeros((m, 1)) # predictions buffer - we set to be 0 for each sample initially\n",
    "    for i in range(m):\n",
    "        predictions_buffer[i, 0] = custom_sequential_model(X[i], W1, b1, W2, b2, W3, b3, w4, b4)\n",
    "    return predictions_buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing our predict function on some random samples I made up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: only length-1 arrays can be converted to Python scalars",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m X_test_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\n\u001b[1;32m      2\u001b[0m     [\u001b[38;5;241m0.066765941\u001b[39m, \u001b[38;5;241m0.149293183\u001b[39m],\n\u001b[1;32m      3\u001b[0m     [\u001b[38;5;241m0.316632126\u001b[39m, \u001b[38;5;241m0.708010957\u001b[39m]\n\u001b[1;32m      4\u001b[0m ])\n\u001b[0;32m----> 5\u001b[0m test_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW1_tmp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb1_tmp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW2_tmp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb2_tmp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW3_tmp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb3_tmp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW4_tmp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb4_tmp\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[17], line 6\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(X, W1, b1, W2, b2, W3, b3, w4, b4)\u001b[0m\n\u001b[1;32m      4\u001b[0m predictions_buffer \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((m, \u001b[38;5;241m1\u001b[39m)) \u001b[38;5;66;03m# predictions buffer - we set to be 0 for each sample initially\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(m):\n\u001b[0;32m----> 6\u001b[0m     \u001b[43mpredictions_buffer\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m custom_sequential_model(X[i], W1, b1, W2, b2, W3, b3, w4, b4)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predictions_buffer\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "X_test_data = np.array([\n",
    "    [0.066765941, 0.149293183],\n",
    "    [0.316632126, 0.708010957]\n",
    "])\n",
    "test_predictions = predict(X_test_data, W1_tmp, b1_tmp, W2_tmp, b2_tmp, W3_tmp, b3_tmp, W4_tmp, b4_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = (test_predictions >= 0.3).astype(int)\n",
    "print(f\"test_predictions:\\n {yhat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now for the actual predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forgot to normalize above, do that now to avoid skewed range of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_layer = tf.keras.layers.Normalization(axis=-1)\n",
    "\n",
    "print(normalized_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_layer.adapt(X)\n",
    "\n",
    "X_normalized = normalized_layer(X)\n",
    "\n",
    "print(X_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating predictions using our custom model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict(X_normalized, W1_tmp, b1_tmp, W2_tmp, b2_tmp, W3_tmp, b3_tmp)\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = np.zeros_like(predictions)\n",
    "for i in range(len(predictions)):\n",
    "    if predictions[i] >= 0.5:\n",
    "        yhat[i] = 1\n",
    "    else:\n",
    "        yhat[i] = 0\n",
    "\n",
    "print(f\"decisions = \\n{yhat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(predictions, y)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
