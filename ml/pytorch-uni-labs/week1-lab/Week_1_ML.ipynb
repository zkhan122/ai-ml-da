{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbC6bkLyj-Bx"
      },
      "source": [
        "# Week 1: Lab set up and test run\n",
        "\n",
        "This week's lab is to help you set up the lab environment using either Colab or on your own computer, and ensure that you can run through code below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tXe5MUBEj-Bz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsGrpR9Hj-B0"
      },
      "source": [
        "## Loading MNIST\n",
        "\n",
        "In this lab, we will be using the MNIST dataset, which is a set of 70,000 small images of digits handwritten by high school students and employees of the US Census Bureau. Each image is labeled with the digit it represents. This set has been studied so much that it is often called the “Hello World” of Machine Learning: whenever people come up with a new classification algorithm, they are curious to see how it will perform on MNIST. Whenever someone learns Machine Learning, sooner or later they tackle MNIST.\n",
        "\n",
        "Scikit-Learn provides many helper functions to download popular datasets. MNIST is one of them. The following code fetches the MNIST dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3e0gmy5bj-B0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0955cc81-bbe3-4d25-f3a7-28a50ecc80fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1797, 64)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_digits\n",
        "digits = load_digits()\n",
        "\n",
        "print(digits.data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print fields of the digits dataset\n",
        "print(\"Keys of the digits dataset:\")\n",
        "print(digits.keys())\n",
        "\n",
        "# Access and print information about the dataset\n",
        "print(\"\\nNumber of samples:\", digits.data.shape[0])\n",
        "print(\"Number of features per sample:\", digits.data.shape[1])\n",
        "print(\"Number of classes:\", len(digits.target_names))\n",
        "\n",
        "# Other relevant information\n",
        "print(\"\\nFeature names:\")\n",
        "print(digits.feature_names)\n",
        "\n",
        "print(\"\\nTarget names:\")\n",
        "print(digits.target_names)\n",
        "\n",
        "# More detailed description\n",
        "print(\"\\nDataset Description:\")\n",
        "print(digits.DESCR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hs3j4_ocx8Yi",
        "outputId": "f092aaf2-bada-4a8f-97bc-b189fd4ba0b6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keys of the digits dataset:\n",
            "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])\n",
            "\n",
            "Number of samples: 1797\n",
            "Number of features per sample: 64\n",
            "Number of classes: 10\n",
            "\n",
            "Feature names:\n",
            "['pixel_0_0', 'pixel_0_1', 'pixel_0_2', 'pixel_0_3', 'pixel_0_4', 'pixel_0_5', 'pixel_0_6', 'pixel_0_7', 'pixel_1_0', 'pixel_1_1', 'pixel_1_2', 'pixel_1_3', 'pixel_1_4', 'pixel_1_5', 'pixel_1_6', 'pixel_1_7', 'pixel_2_0', 'pixel_2_1', 'pixel_2_2', 'pixel_2_3', 'pixel_2_4', 'pixel_2_5', 'pixel_2_6', 'pixel_2_7', 'pixel_3_0', 'pixel_3_1', 'pixel_3_2', 'pixel_3_3', 'pixel_3_4', 'pixel_3_5', 'pixel_3_6', 'pixel_3_7', 'pixel_4_0', 'pixel_4_1', 'pixel_4_2', 'pixel_4_3', 'pixel_4_4', 'pixel_4_5', 'pixel_4_6', 'pixel_4_7', 'pixel_5_0', 'pixel_5_1', 'pixel_5_2', 'pixel_5_3', 'pixel_5_4', 'pixel_5_5', 'pixel_5_6', 'pixel_5_7', 'pixel_6_0', 'pixel_6_1', 'pixel_6_2', 'pixel_6_3', 'pixel_6_4', 'pixel_6_5', 'pixel_6_6', 'pixel_6_7', 'pixel_7_0', 'pixel_7_1', 'pixel_7_2', 'pixel_7_3', 'pixel_7_4', 'pixel_7_5', 'pixel_7_6', 'pixel_7_7']\n",
            "\n",
            "Target names:\n",
            "[0 1 2 3 4 5 6 7 8 9]\n",
            "\n",
            "Dataset Description:\n",
            ".. _digits_dataset:\n",
            "\n",
            "Optical recognition of handwritten digits dataset\n",
            "--------------------------------------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 1797\n",
            "    :Number of Attributes: 64\n",
            "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
            "    :Missing Attribute Values: None\n",
            "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
            "    :Date: July; 1998\n",
            "\n",
            "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
            "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
            "\n",
            "The data set contains images of hand-written digits: 10 classes where\n",
            "each class refers to a digit.\n",
            "\n",
            "Preprocessing programs made available by NIST were used to extract\n",
            "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
            "total of 43 people, 30 contributed to the training set and different 13\n",
            "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
            "4x4 and the number of on pixels are counted in each block. This generates\n",
            "an input matrix of 8x8 where each element is an integer in the range\n",
            "0..16. This reduces dimensionality and gives invariance to small\n",
            "distortions.\n",
            "\n",
            "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
            "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
            "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
            "1994.\n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
            "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
            "    Graduate Studies in Science and Engineering, Bogazici University.\n",
            "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
            "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
            "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
            "    Electrical and Electronic Engineering Nanyang Technological University.\n",
            "    2005.\n",
            "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
            "    Algorithm. NIPS. 2000.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the first few digits\n",
        "num_digits_to_display = 7\n",
        "\n",
        "for i in range(num_digits_to_display):\n",
        "    plt.subplot(1, num_digits_to_display, i + 1)\n",
        "    plt.imshow(digits.images[i], cmap='gray')\n",
        "    plt.title(f\"Digit {i}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "id": "rpgbdSnPw3ek",
        "outputId": "dd885b18-3acb-4e96-a07d-87786a074223"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 7 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "KAQJNVUYj-B1"
      },
      "outputs": [],
      "source": [
        "X_digits = digits.data\n",
        "y_digits = digits.target\n",
        "\n",
        "n_samples = len(X_digits)\n",
        "\n",
        "X_train = X_digits[:round(.9 * n_samples)]\n",
        "y_train = y_digits[:round(.9 * n_samples)]\n",
        "X_test = X_digits[round(.9 * n_samples):]\n",
        "y_test = y_digits[round(.9 * n_samples):]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yi2zYuskj-B1"
      },
      "source": [
        "## KNN classifier\n",
        "\n",
        "\n",
        "Let’s simplify the problem for now and only try to identify one digit—for example, the number 5. This “5-detector” will be an example of a binary classifier, capable of distinguishing between just two classes, 5 and not-5. Let’s create the target vectors for this classification task. Now let’s train the classifier:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "JkYfBiu2j-B2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "cb98cda0-7414-4b9d-a9fc-9827eb2c5071"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(n_jobs=-1, n_neighbors=4, weights='distance')"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_jobs=-1, n_neighbors=4, weights=&#x27;distance&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_jobs=-1, n_neighbors=4, weights=&#x27;distance&#x27;)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "\n",
        "y_train_5 = (y_train == 5)\n",
        "y_test_5 = (y_test == 5)\n",
        "\n",
        "knn_clf = KNeighborsClassifier(n_jobs=-1, weights='distance', n_neighbors=4)\n",
        "knn_clf.fit(X_train, y_train_5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "l5z9bkCNj-B2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "c0bca4b0-1883-45d9-be50-fb4fa22e6adc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 7 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "num_digits_to_display=7\n",
        "\n",
        "for i in range(num_digits_to_display):\n",
        "    plt.subplot(1, num_digits_to_display, i + 1)\n",
        "\n",
        "    # Display the image\n",
        "    plt.imshow(digits.images[1719 - i], cmap='gray')\n",
        "\n",
        "    # Make a prediction\n",
        "    some_digit = digits.data[1719 - i].reshape(1, -1)\n",
        "    classification = knn_clf.predict(some_digit)\n",
        "\n",
        "    # Display the title with the predicted class\n",
        "    plt.title(f\"5? {classification[0]}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CarfJHv9j-B3"
      },
      "source": [
        "## Performance Measures\n",
        "\n",
        "Evaluating a classifier is often significantly trickier than evaluating a regressor, so we will spend a large part of this chapter on this topic. There are many performance measures available, so grab another coffee and get ready to learn many new concepts and acronyms!\n",
        "\n",
        "A good way to evaluate a model is to use cross-validation. Let’s use the cross_val_score() function to evaluate your KNN model using K-fold cross-validation, with three folds. Remember that K-fold crossvalidation means splitting the training set into K-folds (in this case, three), then making predictions and evaluating them on each fold using a model trained on the remaining folds.\n",
        "\n",
        "### Measuring Accuracy Using Cross-Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "zZkMzJTpj-B3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a860c80e-6769-4b9d-f7d4-1dc71bb1cc19"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.99628942, 0.99443414, 0.99628942])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "cross_val_score(knn_clf, X_train, y_train_5, cv=3, scoring=\"accuracy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01g2mcrlj-B3"
      },
      "source": [
        "### Confusion Matrix\n",
        "\n",
        "A much better way to evaluate the performance of a classifier is to look at the confusion matrix. The general idea is to count the number of times instances of class A are classified as class B. For example, to know the number of times the classifier confused images of 5s with 3s, you would look in the 5 th row and 3 rd column of the confusion matrix.\n",
        "\n",
        "To compute the confusion matrix, you first need to have a set of predictions, so they can be compared to the actual targets. You could make predictions on the test set, but let’s keep it untouched for now (remember that you want to use the test set only at the very end of your project, once you have a classifier that you are ready to launch). Instead, you can use the cross_val_predict() function. Just like the cross_val_score() function, cross_val_predict() performs K-fold cross-validation, but instead of returning the evaluation scores, it returns the predictions made on each test fold. This means that you get a clean prediction for each instance in the training set (“clean” meaning that the prediction is made by a model that never saw the data during training).\n",
        "\n",
        "\n",
        "Now you are ready to get the confusion matrix using the confusion_matrix() function. Just pass it the target classes (y_train_5) and the predicted classes (y_train_pred):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "vkYeC44-j-B4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf880f6e-0760-48b0-bf53-af7fb01df365"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1452,    1],\n",
              "       [   6,  158]])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "y_train_pred = cross_val_predict(knn_clf, X_train, y_train_5, cv=3)\n",
        "confusion_matrix(y_train_5, y_train_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxliwRbEj-B4"
      },
      "source": [
        "Each row in a confusion matrix represents an actual class, while each column represents a predicted class. The first row of this matrix considers non-5 images (the negative class): 1,452 of them were correctly classified as non-5s (they are called true negatives), while the remaining 1 was wrongly classified as 5s (false positives). The second row considers the images of 5s (the positive class): 6 were wrongly classified as non-5s (false negatives), while the remaining 158 were correctly classified as 5s (true positives). A perfect classifier would have only true positives and true negatives, so its confusion matrix would have nonzero values only on its main diagonal (top left to bottom right):"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "nav_menu": {},
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": "block",
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}