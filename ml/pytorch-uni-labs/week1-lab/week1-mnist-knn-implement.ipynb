{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "%matplotlib inline\n",
    "import matplotlib as mpl \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'matplotlib' from 'c:\\\\Users\\\\zayaa\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\matplotlib\\\\__init__.py'>\n"
     ]
    }
   ],
   "source": [
    "# rc = run commands\n",
    "mpl.rc(\"axes\", labelsize=14)\n",
    "mpl.rc(\"xtick\", labelsize=12)\n",
    "mpl.rc(\"ytick\", labelsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading MNIST (handwritten digits dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
      "       ...,\n",
      "       [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
      "       [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
      "       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), 'target': array([0, 1, 2, ..., 8, 9, 8]), 'frame': None, 'feature_names': ['pixel_0_0', 'pixel_0_1', 'pixel_0_2', 'pixel_0_3', 'pixel_0_4', 'pixel_0_5', 'pixel_0_6', 'pixel_0_7', 'pixel_1_0', 'pixel_1_1', 'pixel_1_2', 'pixel_1_3', 'pixel_1_4', 'pixel_1_5', 'pixel_1_6', 'pixel_1_7', 'pixel_2_0', 'pixel_2_1', 'pixel_2_2', 'pixel_2_3', 'pixel_2_4', 'pixel_2_5', 'pixel_2_6', 'pixel_2_7', 'pixel_3_0', 'pixel_3_1', 'pixel_3_2', 'pixel_3_3', 'pixel_3_4', 'pixel_3_5', 'pixel_3_6', 'pixel_3_7', 'pixel_4_0', 'pixel_4_1', 'pixel_4_2', 'pixel_4_3', 'pixel_4_4', 'pixel_4_5', 'pixel_4_6', 'pixel_4_7', 'pixel_5_0', 'pixel_5_1', 'pixel_5_2', 'pixel_5_3', 'pixel_5_4', 'pixel_5_5', 'pixel_5_6', 'pixel_5_7', 'pixel_6_0', 'pixel_6_1', 'pixel_6_2', 'pixel_6_3', 'pixel_6_4', 'pixel_6_5', 'pixel_6_6', 'pixel_6_7', 'pixel_7_0', 'pixel_7_1', 'pixel_7_2', 'pixel_7_3', 'pixel_7_4', 'pixel_7_5', 'pixel_7_6', 'pixel_7_7'], 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), 'images': array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n",
      "        [ 0.,  0., 13., ..., 15.,  5.,  0.],\n",
      "        [ 0.,  3., 15., ..., 11.,  8.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  4., 11., ..., 12.,  7.,  0.],\n",
      "        [ 0.,  2., 14., ..., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n",
      "\n",
      "       [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n",
      "        [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
      "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n",
      "\n",
      "       [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n",
      "        [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  9., 16., ...,  0.,  0.,  0.],\n",
      "        [ 0.,  3., 13., ..., 11.,  5.,  0.],\n",
      "        [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n",
      "        [ 0.,  0., 13., ...,  2.,  1.,  0.],\n",
      "        [ 0.,  0., 16., ..., 16.,  5.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  0., 16., ..., 15.,  0.,  0.],\n",
      "        [ 0.,  0., 15., ..., 16.,  0.,  0.],\n",
      "        [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n",
      "\n",
      "       [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 14., ..., 15.,  1.,  0.],\n",
      "        [ 0.,  4., 16., ..., 16.,  7.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n",
      "        [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n",
      "        [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n",
      "\n",
      "       [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n",
      "        [ 0.,  2., 16., ...,  1.,  0.,  0.],\n",
      "        [ 0.,  0., 15., ..., 15.,  0.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  4., 16., ..., 16.,  6.,  0.],\n",
      "        [ 0.,  8., 16., ..., 16.,  8.,  0.],\n",
      "        [ 0.,  1.,  8., ..., 12.,  1.,  0.]]]), 'DESCR': \".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n:Number of Instances: 1797\\n:Number of Attributes: 64\\n:Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n:Missing Attribute Values: None\\n:Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n:Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttps://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n|details-start|\\n**References**\\n|details-split|\\n\\n- C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n  Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n  Graduate Studies in Science and Engineering, Bogazici University.\\n- E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n- Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n  Linear dimensionalityreduction using relevance weighted LDA. School of\\n  Electrical and Electronic Engineering Nanyang Technological University.\\n  2005.\\n- Claudio Gentile. A New Approximate Maximal Margin Classification\\n  Algorithm. NIPS. 2000.\\n\\n|details-end|\\n\"}\n",
      "\n",
      "\n",
      "(1797, 64)\n",
      "(1797, 8, 8)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "\n",
    "print(digits)\n",
    "print(\"\\n\")\n",
    "print(np.shape(digits.data))\n",
    "print(np.shape(digits.images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])\n",
      "Number of samples/record: 1797\n",
      "Number of features per sample: 64\n",
      "Number of classes:  10\n",
      "\n",
      "Feature names: \n",
      "['pixel_0_0', 'pixel_0_1', 'pixel_0_2', 'pixel_0_3', 'pixel_0_4', 'pixel_0_5', 'pixel_0_6', 'pixel_0_7', 'pixel_1_0', 'pixel_1_1', 'pixel_1_2', 'pixel_1_3', 'pixel_1_4', 'pixel_1_5', 'pixel_1_6', 'pixel_1_7', 'pixel_2_0', 'pixel_2_1', 'pixel_2_2', 'pixel_2_3', 'pixel_2_4', 'pixel_2_5', 'pixel_2_6', 'pixel_2_7', 'pixel_3_0', 'pixel_3_1', 'pixel_3_2', 'pixel_3_3', 'pixel_3_4', 'pixel_3_5', 'pixel_3_6', 'pixel_3_7', 'pixel_4_0', 'pixel_4_1', 'pixel_4_2', 'pixel_4_3', 'pixel_4_4', 'pixel_4_5', 'pixel_4_6', 'pixel_4_7', 'pixel_5_0', 'pixel_5_1', 'pixel_5_2', 'pixel_5_3', 'pixel_5_4', 'pixel_5_5', 'pixel_5_6', 'pixel_5_7', 'pixel_6_0', 'pixel_6_1', 'pixel_6_2', 'pixel_6_3', 'pixel_6_4', 'pixel_6_5', 'pixel_6_6', 'pixel_6_7', 'pixel_7_0', 'pixel_7_1', 'pixel_7_2', 'pixel_7_3', 'pixel_7_4', 'pixel_7_5', 'pixel_7_6', 'pixel_7_7']\n",
      "\n",
      "Target names: \n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "\n",
      "Dataset Description: \n",
      ".. _digits_dataset:\n",
      "\n",
      "Optical recognition of handwritten digits dataset\n",
      "--------------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      ":Number of Instances: 1797\n",
      ":Number of Attributes: 64\n",
      ":Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
      ":Missing Attribute Values: None\n",
      ":Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
      ":Date: July; 1998\n",
      "\n",
      "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "\n",
      "The data set contains images of hand-written digits: 10 classes where\n",
      "each class refers to a digit.\n",
      "\n",
      "Preprocessing programs made available by NIST were used to extract\n",
      "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
      "total of 43 people, 30 contributed to the training set and different 13\n",
      "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
      "4x4 and the number of on pixels are counted in each block. This generates\n",
      "an input matrix of 8x8 where each element is an integer in the range\n",
      "0..16. This reduces dimensionality and gives invariance to small\n",
      "distortions.\n",
      "\n",
      "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
      "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
      "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
      "1994.\n",
      "\n",
      "|details-start|\n",
      "**References**\n",
      "|details-split|\n",
      "\n",
      "- C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
      "  Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
      "  Graduate Studies in Science and Engineering, Bogazici University.\n",
      "- E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
      "- Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
      "  Linear dimensionalityreduction using relevance weighted LDA. School of\n",
      "  Electrical and Electronic Engineering Nanyang Technological University.\n",
      "  2005.\n",
      "- Claudio Gentile. A New Approximate Maximal Margin Classification\n",
      "  Algorithm. NIPS. 2000.\n",
      "\n",
      "|details-end|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(digits.keys())\n",
    "\n",
    "print(\"Number of samples/record:\", digits.data.shape[0])\n",
    "print(\"Number of features per sample:\", digits.data.shape[1])\n",
    "print(\"Number of classes: \", len(digits.target_names))\n",
    "\n",
    "print(\"\\nFeature names: \")\n",
    "print(digits.feature_names)\n",
    "\n",
    "print(\"\\nTarget names: \")\n",
    "print(digits.target_names)\n",
    "\n",
    "print(\"\\nDataset Description: \")\n",
    "print(digits.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 7 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the first few digits:\n",
    "num_digits_to_display = 7\n",
    "for i in range(num_digits_to_display):\n",
    "    plt.subplot(1, num_digits_to_display, i+1)\n",
    "    plt.imshow(digits.images[i])\n",
    "    plt.title(f\"Digit {i}\")\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_digits = digits.data\n",
    "Y_digits = digits.target\n",
    "\n",
    "n_samples = len(X_digits)\n",
    "\n",
    "# use 90% of data for training  because in ML we split data IN HALF into training and testing sets\n",
    "\n",
    "# training sets - 90% of data\n",
    "X_train = X_digits[:round(.9 * n_samples)]\n",
    "y_train = Y_digits[:round(.9 * n_samples)]\n",
    "\n",
    "# testing sets - 10% of data\n",
    "X_test = X_digits[round(.9 * n_samples):] \n",
    "y_test = Y_digits[round(.9 * n_samples):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Classifier:\n",
    "\n",
    "Let us first try to test to see if we can allow our model to recognize one digit e.g. 5 \n",
    "\n",
    "To do this, we need a binary classifier to split into 2 classes (results), 5 and not-5.\n",
    "\n",
    "We need to create target vectors for this classification task, and so lets train our classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_jobs=1, n_neighbors=4, weights=&#x27;distance&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;KNeighborsClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\">?<span>Documentation for KNeighborsClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>KNeighborsClassifier(n_jobs=1, n_neighbors=4, weights=&#x27;distance&#x27;)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(n_jobs=1, n_neighbors=4, weights='distance')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "y_train_5 = (y_train == 5) # creates a boolean array of True or False if any of the numbers are 5 or not\n",
    "y_test_5 = (y_test == 5)\n",
    "\n",
    "knn_classifier = KNeighborsClassifier(n_jobs=1, weights=\"distance\", n_neighbors=4)\n",
    "knn_classifier.fit(X_train, y_train_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number 0 : [False]\n",
      "Number 1 : [False]\n",
      "Number 2 : [False]\n",
      "Number 3 : [False]\n",
      "Number 4 : [False]\n",
      "Number 5 : [ True]\n",
      "Number 6 : [False]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 7 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_digits_to_display = 7\n",
    "for i in range(num_digits_to_display):\n",
    "    plt.subplot(1, num_digits_to_display, i+1)\n",
    "    # Display the image\n",
    "    plt.imshow(digits.images[i])\n",
    "\n",
    "    # making the prediction\n",
    "    digit_eval = np.reshape(digits.data[i], (1, -1))\n",
    "    classification = knn_classifier.predict(digit_eval)\n",
    "    print(f\"Number {i} :\", classification)\n",
    "\n",
    "    if classification == True: plt.title(\"Is 5\")\n",
    "    if classification == False: plt.title(\"Not 5\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now let us evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99628942 0.99443414 0.99628942]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "score = cross_val_score(knn_classifier, X_train, y_train_5, cv=3, scoring=\"accuracy\")\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# or instead we can use confusion matrix:\n",
    "    confusion matrix tells us how many times the classifier confused images e.g. 5s with 3s so therefore we would look at the result in the 5th row, 3rd column\n",
    "\n",
    "    Adding on, to compute the confusion matrix, we just have a set of predictions so they can be compared to the actual targets (we normally dont wanna test these predictions on the test set UNTIL THE VERY END)\n",
    "\n",
    "    we can use the cross_val_predict() function to perform k-fold cross validation and so it returns predictions on each test fold like cross_val_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1452    1]\n",
      " [   6  158]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_train_prediction = cross_val_predict(knn_classifier, X_train, y_train_5, cv=3)\n",
    "matrix = confusion_matrix(y_train_5, y_train_prediction)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row in a confusion matrix represents an actual class, while each column represents a predicted class. The first row of this matrix considers non-5 images (the negative class): 1,452 of them were correctly classified as non-5s (they are called TRUE NEGATIVES), while the remaining 1 was wrongly classified as 5s (FALSE POSITIVES). The second row considers the images of 5s (THE POSITIVE CLASS): 6 were wrongly classified as non-5s (FALSE NEGATIVES), while the remaining 158 were correctly classified as 5s (TRUE POSITIVES). A PERFECT CLASSIFER WOULD ONLY HAVE TRUE POSITIVES AND TRUE NEGATIVES, so its confusion matrix would have nonzero values only on its main diagonal (top left to bottom right):"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
